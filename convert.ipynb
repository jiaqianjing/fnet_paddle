{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48d0942-3754-4b35-ba64-6958e2297121",
   "metadata": {},
   "source": [
    "## 导入 huggingface model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb7dbf-1a0c-4fd9-834f-5973b2a8cdbc",
   "metadata": {},
   "source": [
    "### base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c5f224-1b41-4ea4-acc9-a3c27abe2f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import FNetTokenizer, FNetModel\n",
    "tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-base\")\n",
    "model = FNetModel.from_pretrained(\"google/fnet-base\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df0f496-f386-4f36-b7d2-ae89b7711c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pretrained_model/torch/base/tokenizer_config.json',\n",
       " 'pretrained_model/torch/base/special_tokens_map.json',\n",
       " 'pretrained_model/torch/base/spiece.model',\n",
       " 'pretrained_model/torch/base/added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save base model\n",
    "torch_large_model_path = 'pretrained_model/torch/base'\n",
    "model.save_pretrained(torch_large_model_path)\n",
    "tokenizer.save_pretrained(torch_large_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25a31a-5912-47bd-81a8-9b28d69b23ab",
   "metadata": {},
   "source": [
    "### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e7daae-f2d5-40be-88ce-1b87058976a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-large were not used when initializing FNetModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import FNetTokenizer, FNetModel\n",
    "tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-large\")\n",
    "model = FNetModel.from_pretrained(\"google/fnet-large\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "output = model(**encoded_input)\n",
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ddc3dec-7778-4f88-a972-54915e408294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pretrained_model/torch/large/tokenizer_config.json',\n",
       " 'pretrained_model/torch/large/special_tokens_map.json',\n",
       " 'pretrained_model/torch/large/spiece.model',\n",
       " 'pretrained_model/torch/large/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save large model\n",
    "torch_large_model_path = 'pretrained_model/torch/large'\n",
    "model.save_pretrained(torch_large_model_path)\n",
    "tokenizer.save_pretrained(torch_large_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f11078-76c9-471a-8a40-fc5e7b3061f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72ac13-6d6b-464e-8fa3-c22d2c86486d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595e12ab-72b9-4410-970f-9952f32a7763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f9bdee-5107-4fe0-8dfd-2a9aa6181776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('/workspace/fnet_paddle/PaddleNLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9937ca70-3e00-4d39-a98f-c2f9076ba2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlenlp as ppnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad15def-1b41-46fd-9a69-87c67f15af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_large_model_path = 'pretrained_model/torch/large'\n",
    "p_tokenizer = ppnlp.transformers.FNetTokenizer.from_pretrained(torch_large_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c191e11d-1908-46a4-97b9-d11fa865cfaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4, 109, 6286, 16680, 275, 1145, 5],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tokenizer('hello, my bro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559832bf-17db-46b2-a21c-9461d086a497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
