{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48d0942-3754-4b35-ba64-6958e2297121",
   "metadata": {},
   "source": [
    "## 导入 huggingface model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8eeb16-bf5f-4108-aa58-b48da69eedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# load transformer 源码\n",
    "sys.path.append('/workspace/transformers/src/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb7dbf-1a0c-4fd9-834f-5973b2a8cdbc",
   "metadata": {},
   "source": [
    "### base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c5f224-1b41-4ea4-acc9-a3c27abe2f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import FNetTokenizer, FNetModel\n",
    "tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-base\")\n",
    "model = FNetModel.from_pretrained(\"google/fnet-base\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df0f496-f386-4f36-b7d2-ae89b7711c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pretrained_model/torch/base/tokenizer_config.json',\n",
       " 'pretrained_model/torch/base/special_tokens_map.json',\n",
       " 'pretrained_model/torch/base/spiece.model',\n",
       " 'pretrained_model/torch/base/added_tokens.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save base model\n",
    "torch_base_model_path = 'pretrained_model/torch/base'\n",
    "model.save_pretrained(torch_base_model_path)\n",
    "tokenizer.save_pretrained(torch_base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5828e0e-7cef-4f4c-a685-d34def6dbdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.position_ids torch.Size([1, 512])\n",
      "embeddings.word_embeddings.weight torch.Size([32000, 768])\n",
      "embeddings.position_embeddings.weight torch.Size([512, 768])\n",
      "embeddings.token_type_embeddings.weight torch.Size([4, 768])\n",
      "embeddings.LayerNorm.weight torch.Size([768])\n",
      "embeddings.LayerNorm.bias torch.Size([768])\n",
      "embeddings.projection.weight torch.Size([768, 768])\n",
      "embeddings.projection.bias torch.Size([768])\n",
      "encoder.layer.0.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.0.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.0.output.dense.bias torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.1.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.1.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.1.output.dense.bias torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.2.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.2.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.2.output.dense.bias torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.3.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.3.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.3.output.dense.bias torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.4.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.4.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.4.output.dense.bias torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.5.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.5.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.5.output.dense.bias torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.6.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.6.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.6.output.dense.bias torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.7.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.7.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.7.output.dense.bias torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.8.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.8.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.8.output.dense.bias torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.9.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.9.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.9.output.dense.bias torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.10.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.10.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.10.output.dense.bias torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.11.fourier.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.11.fourier.output.LayerNorm.bias torch.Size([768])\n",
      "encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n",
      "encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n",
      "encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n",
      "encoder.layer.11.output.dense.bias torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n",
      "encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n",
      "pooler.dense.weight torch.Size([768, 768])\n",
      "pooler.dense.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for k,v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235651d1-e7e5-4b16-b07f-b8c468a729d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNetModel(\n",
       "  (embeddings): FNetEmbeddings(\n",
       "    (word_embeddings): Embedding(32000, 768, padding_idx=3)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(4, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): FNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): FNetLayer(\n",
       "        (fourier): FNetFourierTransform(\n",
       "          (self): FNetBasicFourierTransform()\n",
       "          (output): FNetBasicOutput(\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): FNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): FNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): FNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25a31a-5912-47bd-81a8-9b28d69b23ab",
   "metadata": {},
   "source": [
    "### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2e7daae-f2d5-40be-88ce-1b87058976a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-large were not used when initializing FNetModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 1024]), torch.Size([1, 1024]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import FNetTokenizer, FNetModel\n",
    "tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-large\")\n",
    "model = FNetModel.from_pretrained(\"google/fnet-large\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "output = model(**encoded_input)\n",
    "output.last_hidden_state.shape, output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ddc3dec-7778-4f88-a972-54915e408294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pretrained_model/torch/large/tokenizer_config.json',\n",
       " 'pretrained_model/torch/large/special_tokens_map.json',\n",
       " 'pretrained_model/torch/large/spiece.model',\n",
       " 'pretrained_model/torch/large/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save large model\n",
    "torch_large_model_path = 'pretrained_model/torch/large'\n",
    "model.save_pretrained(torch_large_model_path)\n",
    "tokenizer.save_pretrained(torch_large_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e24cd-dbb2-4786-9282-b5304e9a556b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
