{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd6aa35-6b9b-4d9f-8b41-4db436a93bd5",
   "metadata": {},
   "source": [
    "## 模型参数 torch 转换 paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89906706-e028-4de8-ae6e-c278a7768a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  embeddings.position_ids \t torch.Size([1, 512])\n",
      "p:  embeddings.position_ids \t [1, 512] \n",
      "\n",
      "t:  embeddings.word_embeddings.weight \t torch.Size([32000, 1024])\n",
      "p:  embeddings.word_embeddings.weight \t [32000, 1024] \n",
      "\n",
      "t:  embeddings.position_embeddings.weight \t torch.Size([512, 1024])\n",
      "p:  embeddings.position_embeddings.weight \t [512, 1024] \n",
      "\n",
      "t:  embeddings.token_type_embeddings.weight \t torch.Size([4, 1024])\n",
      "p:  embeddings.token_type_embeddings.weight \t [4, 1024] \n",
      "\n",
      "t:  embeddings.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  embeddings.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  embeddings.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  embeddings.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  embeddings.projection.weight \t torch.Size([1024, 1024])\n",
      "p:  embeddings.projection.weight \t [1024, 1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  embeddings.projection.bias \t torch.Size([1024])\n",
      "p:  embeddings.projection.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.0.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.0.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.0.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.0.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.0.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.0.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.0.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.0.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.0.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.0.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.0.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.0.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.0.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.0.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.0.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.0.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.1.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.1.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.1.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.1.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.1.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.1.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.1.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.1.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.1.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.1.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.1.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.1.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.1.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.1.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.1.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.1.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.2.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.2.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.2.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.2.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.2.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.2.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.2.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.2.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.2.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.2.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.2.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.2.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.2.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.2.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.2.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.2.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.3.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.3.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.3.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.3.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.3.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.3.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.3.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.3.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.3.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.3.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.3.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.3.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.3.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.3.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.3.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.3.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.4.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.4.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.4.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.4.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.4.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.4.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.4.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.4.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.4.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.4.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.4.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.4.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.4.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.4.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.4.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.4.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.5.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.5.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.5.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.5.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.5.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.5.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.5.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.5.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.5.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.5.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.5.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.5.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.5.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.5.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.5.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.5.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.6.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.6.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.6.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.6.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.6.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.6.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.6.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.6.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.6.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.6.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.6.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.6.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.6.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.6.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.6.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.6.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.7.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.7.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.7.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.7.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.7.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.7.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.7.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.7.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.7.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.7.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.7.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.7.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.7.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.7.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.7.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.7.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.8.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.8.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.8.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.8.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.8.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.8.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.8.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.8.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.8.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.8.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.8.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.8.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.8.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.8.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.8.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.8.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.9.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.9.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.9.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.9.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.9.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.9.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.9.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.9.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.9.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.9.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.9.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.9.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.9.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.9.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.9.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.9.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.10.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.10.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.10.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.10.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.10.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.10.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.10.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.10.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.10.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.10.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.10.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.10.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.10.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.10.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.10.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.10.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.11.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.11.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.11.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.11.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.11.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.11.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.11.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.11.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.11.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.11.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.11.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.11.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.11.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.11.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.11.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.11.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.12.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.12.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.12.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.12.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.12.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.12.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.12.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.12.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.12.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.12.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.12.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.12.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.12.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.12.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.12.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.12.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.13.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.13.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.13.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.13.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.13.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.13.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.13.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.13.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.13.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.13.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.13.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.13.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.13.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.13.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.13.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.13.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.14.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.14.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.14.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.14.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.14.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.14.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.14.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.14.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.14.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.14.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.14.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.14.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.14.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.14.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.14.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.14.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.15.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.15.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.15.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.15.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.15.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.15.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.15.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.15.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.15.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.15.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.15.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.15.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.15.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.15.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.15.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.15.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.16.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.16.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.16.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.16.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.16.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.16.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.16.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.16.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.16.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.16.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.16.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.16.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.16.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.16.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.16.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.16.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.17.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.17.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.17.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.17.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.17.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.17.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.17.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.17.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.17.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.17.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.17.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.17.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.17.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.17.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.17.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.17.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.18.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.18.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.18.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.18.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.18.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.18.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.18.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.18.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.18.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.18.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.18.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.18.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.18.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.18.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.18.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.18.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.19.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.19.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.19.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.19.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.19.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.19.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.19.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.19.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.19.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.19.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.19.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.19.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.19.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.19.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.19.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.19.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.20.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.20.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.20.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.20.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.20.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.20.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.20.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.20.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.20.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.20.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.20.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.20.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.20.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.20.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.20.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.20.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.21.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.21.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.21.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.21.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.21.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.21.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.21.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.21.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.21.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.21.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.21.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.21.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.21.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.21.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.21.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.21.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.22.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.22.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.22.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.22.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.22.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.22.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.22.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.22.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.22.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.22.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.22.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.22.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.22.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.22.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.22.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.22.output.layer_norm.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.23.fourier.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.23.fourier.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.23.fourier.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.23.fourier.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.23.intermediate.dense.weight \t torch.Size([4096, 1024])\n",
      "p:  encoder.layers.23.intermediate.dense.weight \t [1024, 4096] \n",
      "\n",
      "t:  encoder.layer.23.intermediate.dense.bias \t torch.Size([4096])\n",
      "p:  encoder.layers.23.intermediate.dense.bias \t [4096] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  encoder.layer.23.output.dense.weight \t torch.Size([1024, 4096])\n",
      "p:  encoder.layers.23.output.dense.weight \t [4096, 1024] \n",
      "\n",
      "t:  encoder.layer.23.output.dense.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.23.output.dense.bias \t [1024] \n",
      "\n",
      "t:  encoder.layer.23.output.LayerNorm.weight \t torch.Size([1024])\n",
      "p:  encoder.layers.23.output.layer_norm.weight \t [1024] \n",
      "\n",
      "t:  encoder.layer.23.output.LayerNorm.bias \t torch.Size([1024])\n",
      "p:  encoder.layers.23.output.layer_norm.bias \t [1024] \n",
      "\n",
      "transpose(permute) ---------->\n",
      "t:  pooler.dense.weight \t torch.Size([1024, 1024])\n",
      "p:  pooler.dense.weight \t [1024, 1024] \n",
      "\n",
      "t:  pooler.dense.bias \t torch.Size([1024])\n",
      "p:  pooler.dense.bias \t [1024] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch_base_model_path = 'pretrained_model/torch/base/pytorch_model.bin'\n",
    "torch_large_model_path = 'pretrained_model/torch/large/pytorch_model.bin'\n",
    "\n",
    "paddle_base_model_path = \"pretrained_model/temp/paddle/base/model_state.pdparams\"\n",
    "paddle_large_model_path = \"pretrained_model/temp/paddle/large/model_state.pdparams\"\n",
    "\n",
    "is_base = False\n",
    "\n",
    "if is_base:\n",
    "    torch_model_path = torch_base_model_path\n",
    "    paddle_model_path = paddle_base_model_path\n",
    "else:\n",
    "    torch_model_path = torch_large_model_path\n",
    "    paddle_model_path = paddle_large_model_path\n",
    "    \n",
    "torch_state_dict = torch.load(torch_model_path)\n",
    "\n",
    "paddle_state_dict = {}\n",
    "\n",
    "# State_dict's keys mapping: from torch to paddle\n",
    "keys_dict = {\n",
    "    # about encoder layer\n",
    "    'LayerNorm': 'layer_norm',\n",
    "    'encoder.layer': 'encoder.layers'\n",
    "}\n",
    "\n",
    "\n",
    "for torch_key in torch_state_dict:\n",
    "    paddle_key = torch_key\n",
    "    for k in keys_dict:\n",
    "        if k in paddle_key:\n",
    "            paddle_key = paddle_key.replace(k, keys_dict[k])\n",
    "\n",
    "    if ('map_fc' in paddle_key) or ('glyph_map' in paddle_key) or ('linear' in paddle_key) or ('proj' in  paddle_key) or ('vocab' in  paddle_key and 'weight' in  paddle_key) or (\"dense.weight\" in paddle_key) or ('transform.weight' in paddle_key) or ('seq_relationship.weight' in paddle_key):\n",
    "        print(\"transpose(permute) ---------->\")\n",
    "        paddle_state_dict[paddle_key] = paddle.to_tensor(torch_state_dict[torch_key].cpu().numpy().transpose())\n",
    "    else:\n",
    "        paddle_state_dict[paddle_key] = paddle.to_tensor(torch_state_dict[torch_key].cpu().numpy())\n",
    "\n",
    "    print(\"t: \", torch_key,\"\\t\", torch_state_dict[torch_key].shape)\n",
    "    print(\"p: \", paddle_key, \"\\t\", paddle_state_dict[paddle_key].shape, \"\\n\")\n",
    "\n",
    "paddle.save(paddle_state_dict, paddle_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41e926-fd37-45c3-8ed0-90050410577d",
   "metadata": {},
   "source": [
    "## 对比前项精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcb058-d7ac-47e0-ba0a-5b21d2903e10",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9170fa73-e721-40c9-b805-7da2806477ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-base were not used when initializing FNetModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "from transformers import FNetTokenizer, FNetModel\n",
    "torch_tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-base\")\n",
    "torch_model = FNetModel.from_pretrained(\"google/fnet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a613c595-c760-4789-a983-363245d17f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98320f5e-0a8b-47d5-9215-f62a43da0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_prediction_logits shape:(1, 12, 768)\n",
      "torch_prediction_logits:[[[ 4.4527473  -0.10137583 -0.21348645 ...  0.36847726 -0.23560826\n",
      "   -0.25296995]\n",
      "  [ 0.18779421 -0.39948907  0.23660113 ...  0.19996837  0.2783861\n",
      "    0.27940997]\n",
      "  [ 0.17300639  0.0606944  -0.47870204 ...  0.05200686 -1.295673\n",
      "    0.578657  ]\n",
      "  ...\n",
      "  [ 0.17106001  0.00485597 -0.06762558 ... -0.3548019  -0.82001925\n",
      "    0.01953557]\n",
      "  [ 0.06859297  0.23336133 -0.57087415 ... -0.3022466  -0.58877695\n",
      "   -0.11472143]\n",
      "  [ 0.24348916  0.1635376   0.36463982 ...  0.5811312  -0.60914195\n",
      "   -0.32033262]]]\n"
     ]
    }
   ],
   "source": [
    "torch_model.eval()\n",
    "torch_inputs = torch_tokenizer(text, return_tensors=\"pt\")\n",
    "torch_outputs = torch_model(**torch_inputs)\n",
    "\n",
    "torch_logits = torch_outputs[0]\n",
    "torch_array = torch_logits.cpu().detach().numpy()\n",
    "print(\"torch_prediction_logits shape:{}\".format(torch_array.shape))\n",
    "print(\"torch_prediction_logits:{}\".format(torch_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74f12e7-dee0-4766-aa65-42e21a392bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1127 20:28:01.890157   919 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 6.0, Driver API Version: 11.0, Runtime API Version: 11.0\n",
      "W1127 20:28:01.894001   919 device_context.cc:465] device: 0, cuDNN Version: 8.0.\n"
     ]
    }
   ],
   "source": [
    "# paddle\n",
    "import os, sys\n",
    "import paddle\n",
    "sys.path.append('/workspace/fnet_paddle/PaddleNLP')\n",
    "import paddlenlp as ppnlp\n",
    "torch_large_model_path = 'pretrained_model/torch/large'\n",
    "paddle_tokenizer = ppnlp.transformers.FNetTokenizer.from_pretrained(torch_large_model_path)\n",
    "\n",
    "paddle_model = ppnlp.transformers.FNetModel()\n",
    "param_dict = paddle.load(paddle_base_model_path)\n",
    "paddle_model.load_dict(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23da363b-ab46-40e2-8cf6-3dcf4c76a54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle_prediction_logits shape:(1, 12, 768)\n",
      "paddle_prediction_logits:[[[ 4.4526024e+00 -1.0144000e-01 -2.1346147e-01 ...  3.6845985e-01\n",
      "   -2.3564060e-01 -2.5293329e-01]\n",
      "  [ 1.8808359e-01 -3.9938882e-01  2.3694393e-01 ...  2.0020518e-01\n",
      "    2.7856782e-01  2.7908224e-01]\n",
      "  [ 1.7336315e-01  6.0770631e-02 -4.7835657e-01 ...  5.1935472e-02\n",
      "   -1.2956736e+00  5.7832038e-01]\n",
      "  ...\n",
      "  [ 1.7099635e-01  4.0750708e-03 -6.7396842e-02 ... -3.5490695e-01\n",
      "   -8.1969118e-01  1.9487010e-02]\n",
      "  [ 6.7856006e-02  2.3314802e-01 -5.7079792e-01 ... -3.0198133e-01\n",
      "   -5.8851326e-01 -1.1473138e-01]\n",
      "  [ 2.4360198e-01  1.6350693e-01  3.6484715e-01 ...  5.8138633e-01\n",
      "   -6.0873306e-01 -3.2016295e-01]]]\n"
     ]
    }
   ],
   "source": [
    "paddle_model.eval()\n",
    "paddle_inputs = paddle_tokenizer(text)\n",
    "paddle_inputs = {k:paddle.to_tensor([v]) for (k, v) in paddle_inputs.items()}\n",
    "paddle_outputs = paddle_model(**paddle_inputs)\n",
    "\n",
    "paddle_logits = paddle_outputs[0]\n",
    "paddle_array = paddle_logits.numpy()\n",
    "print(\"paddle_prediction_logits shape:{}\".format(paddle_array.shape))\n",
    "print(\"paddle_prediction_logits:{}\".format(paddle_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272222eb-f03e-43f7-a7c0-ce0e23c08d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012811422\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "assert torch_array.shape == paddle_array.shape, \"the output logits should have the same shape, but got : {} and {} instead\".format(torch_array.shape, paddle_array.shape)\n",
    "diff = torch_array - paddle_array\n",
    "print(np.amax(abs(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "574ca949-61dd-431a-b874-0b0493b491f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pretrained model\n",
    "base_model = 'pretrained_model/paddle/base/'\n",
    "paddle_model.save_pretrained(base_model)\n",
    "paddle_tokenizer.save_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d3eae-af45-4c97-b8c3-4756b697654b",
   "metadata": {},
   "source": [
    "### large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e29429c8-b44c-4665-bf13-f8d1034148a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/fnet-large were not used when initializing FNetModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing FNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "from transformers import FNetTokenizer, FNetModel\n",
    "torch_tokenizer = FNetTokenizer.from_pretrained(\"google/fnet-large\")\n",
    "torch_model = FNetModel.from_pretrained(\"google/fnet-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3440fe50-1975-44d5-ae33-417e456238c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "388c2c8c-74d3-4fd4-aecc-f3bb56613a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_prediction_logits shape:(1, 12, 1024)\n",
      "torch_prediction_logits:[[[-0.1167793  -0.44756714 -0.51739615 ... -0.19486761 -0.42286307\n",
      "   -0.68805295]\n",
      "  [-0.05607523  0.16956906  0.731847   ... -0.23074943 -0.02952154\n",
      "    0.42456526]\n",
      "  [-0.09154158  0.23390733  0.12532961 ... -0.39507478  0.2645798\n",
      "    0.27237514]\n",
      "  ...\n",
      "  [ 0.29037276 -0.2935935  -0.72729474 ... -0.10259533  0.09559726\n",
      "   -0.27696082]\n",
      "  [ 0.07809267  0.3788107   0.45179468 ...  0.31190634  0.15828757\n",
      "    0.17926018]\n",
      "  [ 0.5804361  -0.18722543  0.3022339  ...  0.6312446   0.5981479\n",
      "    0.42219177]]]\n"
     ]
    }
   ],
   "source": [
    "torch_model.eval()\n",
    "torch_inputs = torch_tokenizer(text, return_tensors=\"pt\")\n",
    "torch_outputs = torch_model(**torch_inputs)\n",
    "\n",
    "torch_logits = torch_outputs[0]\n",
    "torch_array = torch_logits.cpu().detach().numpy()\n",
    "print(\"torch_prediction_logits shape:{}\".format(torch_array.shape))\n",
    "print(\"torch_prediction_logits:{}\".format(torch_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f13d2b-8094-45ee-b328-932b951dd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paddle\n",
    "import os, sys\n",
    "import paddle\n",
    "sys.path.append('/workspace/fnet_paddle/PaddleNLP')\n",
    "import paddlenlp as ppnlp\n",
    "torch_large_model_path = 'pretrained_model/torch/large'\n",
    "paddle_tokenizer = ppnlp.transformers.FNetTokenizer.from_pretrained(torch_large_model_path)\n",
    "\n",
    "paddle_model = ppnlp.transformers.FNetModel(hidden_size=1024, num_hidden_layers=24, intermediate_size=4096)\n",
    "param_dict = paddle.load(paddle_large_model_path)\n",
    "paddle_model.load_dict(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6871160a-7904-48b2-abb0-dbb64cb06165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle_prediction_logits shape:(1, 12, 1024)\n",
      "paddle_prediction_logits:[[[-0.11672818 -0.44755128 -0.51742613 ... -0.19497725 -0.4228959\n",
      "   -0.68803114]\n",
      "  [-0.05620277  0.16907008  0.73102087 ... -0.23174654 -0.02900139\n",
      "    0.42496818]\n",
      "  [-0.09160376  0.23406659  0.12481955 ... -0.39578077  0.26496872\n",
      "    0.27206653]\n",
      "  ...\n",
      "  [ 0.2899852  -0.2933667  -0.72708374 ... -0.10251513  0.09553225\n",
      "   -0.27669966]\n",
      "  [ 0.07795223  0.37862352  0.4516726  ...  0.31222463  0.15768367\n",
      "    0.17931624]\n",
      "  [ 0.5808299  -0.18676645  0.302684   ...  0.6309175   0.5978787\n",
      "    0.42150334]]]\n"
     ]
    }
   ],
   "source": [
    "paddle_model.eval()\n",
    "paddle_inputs = paddle_tokenizer(text)\n",
    "paddle_inputs = {k:paddle.to_tensor([v]) for (k, v) in paddle_inputs.items()}\n",
    "paddle_outputs = paddle_model(**paddle_inputs)\n",
    "\n",
    "paddle_logits = paddle_outputs[0]\n",
    "paddle_array = paddle_logits.numpy()\n",
    "print(\"paddle_prediction_logits shape:{}\".format(paddle_array.shape))\n",
    "print(\"paddle_prediction_logits:{}\".format(paddle_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f94258c-eb21-426f-af06-60614d0a8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016028583\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "assert torch_array.shape == paddle_array.shape, \"the output logits should have the same shape, but got : {} and {} instead\".format(torch_array.shape, paddle_array.shape)\n",
    "diff = torch_array - paddle_array\n",
    "print(np.amax(abs(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e89e3ec7-9b08-4e8a-ac5e-4369a794d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pretrained model\n",
    "base_model = 'pretrained_model/paddle/large/'\n",
    "paddle_model.save_pretrained(base_model)\n",
    "paddle_tokenizer.save_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e4974-b831-450e-b1c5-d719d5d7ac5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
